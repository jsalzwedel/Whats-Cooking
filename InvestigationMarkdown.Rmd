---
title: "Exploring Ingredients Data Set"
author: "jsalzwedel"
date: "09/13/2015"
output: html_document
---

Let's take a look at the Kaggle "What's cooking" data set.  The goal of the
competition is to predict the cuisine of a recipe based on the recipe's 
ingredients.

# Exploratory analysis

## Read in the data

The training and test files are in the json format.  [This site](http://rstudio-pubs-static.s3.amazonaws.com/31702_9c22e3d1a0c44968a4a1f9656f1800ab.html) makes a pretty
strong argument that the jsonlite library is generally the best package to use
for parsing json data.


```{r, message=FALSE}
library(jsonlite)
file <- "train.json"
trainFromJSON <- fromJSON(txt=file)
```

The dplyr::tbl package makes viewing data much more convenient.

```{r}
library(dplyr)
options(dplyr.width = Inf)
train <- tbl_df(trainFromJSON)
```

## Preliminary look

Let's take a quick look at the data.

```{r}
head(train,2)
```

We have three columns: ID of the recipe, type of cuisine, and list of
ingredients.  The ingredients entry for a given recipe is a list of character
vectors, one for each ingredient.  We'll have to split those apart later.

What are the unique cuisine types?

```{r}
unique(train$cuisine)
```

How many times does each cuisine appear?

```{r}
cuisineFrequency <- count(train, cuisine, sort = TRUE)
```


# Analysis

## Strategy

We want to look at each ingredient and see how often it is used in a given
type of cuisine.  There are many ways to use this information.  The simplest
might be to ascribe a single cuisine to each ingredient based on where it is
used most.  When we want to make predictions, each ingredient in a recipe
will weight that recipe towards a certain cuisine.  We can then then add up the
weights to see which cuisine is most favored.

Our analysis strategy will be as follows:

- Make a new data table with a row for each ingredient from each recipe.  We'll
keep the cuisine and recipe ID as additional columns.  

- For each ingredient, see where it is most often used, and associate it with
that type of cuisine.  Here we need to be careful to not be biased by the raw
number of recipes for any given cuisine. For example, cabbage might be used in 
10/100 French recipes, but in 5/5 Korean recipes.

- Make a new data table for the test set with a row for each recipe.

- Use the previously determined ingredient weights to determine which cuisine 
has a plurality among the ingredients.


## Reformatting the data

Let's make a new data table for the ingredients.  First, unpack the list of
ingredients.  Also, keep track of how many ingredients belong to each recipe.
```{r}
ingredientList <- unlist(train$ingredients)
nlengths <- sapply(train$ingredients, length)
mean(nlengths)
```
The averge recipe has about `r round(mean(nlengths))` ingredients.

Now make the data table

```{r}
ingredients <- data.frame(id = rep(train$id, nlengths),
                        cuisine = rep(train$cuisine, nlengths),
                        ingredient = ingredientList)
ingredients <- tbl_df(ingredients)
```



## Looking at the ingredients

Let's get a list of unique ingredients.

```{r}
uniqueIng <- unique(ingredients$ingredient)
```

Let's tabulate cuisines by ingredient.

```{r}
occurances <- count(ingredients, ingredient, cuisine, sort=TRUE)
print(occurances, n=50)
```

For a given ingredient, which cuisine appears the most often?  When we try to 
predict cuisines, that ingredient will "vote" for its associated cuisine

```{r}
votes <- occurances %>% group_by(ingredient) %>% top_n(n=1, wt = n)
votes <- rename(votes, cuisine.vote = cuisine, n.votes = n)
```

Note that if an ingredient has two cuisines that tie for max occurances, it will
get a row for each of them.  For now, I guess that means that that lucky (and
indecisive) ingredient gets two votes!

## Voting with the training set

Now that we have a preferred cuisine for each ingredient, let's take the
training recipes and let their ingredients vote on which kind of cuisine they
probably are.  Let's hope for a reasonable success rate!

```{r}
trainVotes <- inner_join(ingredients, votes)
voteTally <- count(trainVotes, id, cuisine.vote, sort=TRUE)
voteWinners <- voteTally %>% group_by(id) %>% top_n(n=1, wt = n)
voteWinners <- transmute(voteWinners, cuisine.vote)
voteWinners
```

There are still some ties (Recipe 8 has four votes for italian and four for
southern_us).  We can break this tie by choosing the cuisine which appears more
often in the overall training dataset.

```{r}
ties <- voteWinners %>% group_by(id) %>% filter(n() > 1)
ties <- rename(ties, cuisine = cuisine.vote)
ties <- inner_join(ties, cuisineFrequency)
tieBreaker <- ties %>% group_by(id) %>% top_n(n=1, wt = n)
tieBreaker <- transmute(tieBreaker, cuisine.choice = cuisine)
```

Let's use this to remove the ties in voteWinners.

```{r}
voteWinners <- left_join(voteWinners,tieBreaker)
voteWinners[is.na(voteWinners$cuisine.choice),]$cuisine.choice <- as.character(voteWinners[is.na(voteWinners$cuisine.choice),]$cuisine.vote)
voteWinners <- transmute(voteWinners, cuisine.choice)
voteFinal <- distinct(voteWinners)
```

Now we'll merge voteFinal with the training set and see how often we guess
correctly.

```{r}
trainingGuess <- left_join(train, voteFinal)
```

So how did we do?

```{r}
# Distinct recipes:
total <- length(trainingGuess$id)
# Recipes we got correct:
ncorrect <- length(which(trainingGuess$cuisine == trainingGuess$cuisine.choice))
```

Well, we managed to get `r round(ncorrect/total, digits = 2)` correct.
Hopefully that's not too bad for a first try!

## Applying solution to the test set

Let's take the scheme from above and try it out on the test set!

```{r}
fileTest <- "test.json"
testFromJSON <- fromJSON(txt=fileTest)
test <- tbl_df(testFromJSON)
```

Break down the recipes by ingredient:
```{r}
testIngredientList <- unlist(test$ingredients)
testNlengths <- sapply(test$ingredients, length)
testIngredients <- data.frame(id = rep(test$id, testNlengths),
                        ingredient = testIngredientList)
testIngredients <- tbl_df(testIngredients)
```

Let's merge our voting scheme with the ingredient list.  Inner_join will
exclude ingredients that we don't have any vote for.

```{r}
testVotes <- inner_join(testIngredients, votes)
testVoteTally <- count(testVotes, id, cuisine.vote, sort=TRUE)
testVoteWinners <- testVoteTally %>% group_by(id) %>% top_n(n=1, wt = n)
testVoteWinners <- transmute(testVoteWinners, cuisine.vote)
testVoteWinners
```

Again, we'll remove ties.

```{r}
testTies <- testVoteWinners %>% group_by(id) %>% filter(n() > 1)
testTies <- rename(testTies, cuisine = cuisine.vote)
testTies <- inner_join(testTies, cuisineFrequency)
testTieBreaker <- testTies %>% group_by(id) %>% top_n(n=1, wt = n)
testTieBreaker <- transmute(testTieBreaker, cuisine.choice = cuisine)
testVoteWinners <- left_join(testVoteWinners, testTieBreaker)
testVoteWinners[is.na(testVoteWinners$cuisine.choice),]$cuisine.choice <- 
    as.character(testVoteWinners[is.na(testVoteWinners$cuisine.choice),]$cuisine.vote)
testVoteWinners <- transmute(testVoteWinners, cuisine.choice)
```

Our prediction for each recipe's cuisine:

```{r}
prediction <- distinct(testVoteWinners)
prediction <- rename(prediction, cuisine = cuisine.choice)
write.csv(prediction, "prediction.csv", row.names = FALSE, quote=FALSE)
```
